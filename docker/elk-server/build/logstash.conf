######### Input #########
input {
  file {
    path => "/Users/sebastienmuller/comperio/projects/DIFI/projects/dcat-harvester/docker/logs/dcat-harvester.log"
    start_position => "beginning"
    sincedb_path => "/dev/null"
  }
}
######### Input #########

######### Filter #########
filter {
  # Extract event severity, timestamp and logevent type
  grok {
    match => { "message" => "%{DATESTAMP:timestamp} %{WORD:severity}.+?([a-zA-Z]+\.)+%{WORD:logger}.+?\- %{GREEDYDATA:rawContent}" }
      tag_on_failure => []
  }

  ######### DcatAdminController logger for adding/deleting crawlers #########
  if "DcatAdminController" in [logger] {
    mutate {
      add_field => {
        "eventType" => "crawlerAdmin"
        "index" => "true"
      }
    }
    grok {
      match => { "rawContent" => "%{WORD:action} ([a-zA-Z]+ )+%{GREEDYDATA:content}" }
      tag_on_failure => []
    }
    if "Added" in [action] {
      kv {
        source => "content"
        field_split => ", "
        value_split => ":"
        }
      mutate {
        remove_field => [ "content, rawContent, logger" ]
      }
    }
    if "Deleted" in [action] {
      mutate {
        add_field => {
          "crawler_id" => "%{content}"
        }
        remove_field => [ "content, rawContent, logger" ]
      }
    }
  }
  ######### DcatAdminController logger for adding/deleting crawlers #########

  ######### UserAdminRestController logger for adding/deleting users #########
  if "UserAdminRestController" in [logger] {
  mutate {
    add_field => {
      "eventType" => "userAdmin"
      "index" => "true"
    }
  }
    grok {
      match => { "rawContent" => "%{WORD:action} ([a-zA-Z]+ )+%{GREEDYDATA:user_name}" }
      tag_on_failure => []
    }
  }
  ######### UserAdminRestController logger for adding/deleting users #########

  ######### CrawlerJob logger for start/end crawlers #########
  if "CrawlerJob" in [logger] {
    mutate {
      add_field => {
        "eventType" => "crawlerOperation"
        "index" => "true"
      }
    }
    grok {
      match => { "rawContent" => "%{WORD:action} ([a-zA-Z]+ )+%{GREEDYDATA:content}" }
      tag_on_failure => []
    }
    kv {
      source => "content"
      field_split => ", "
      value_split => ":"
    }
    mutate {
      remove_field => [ "content, rawContent, logger" ]
    }

  }
  ######### CrawlerJob logger for start/end crawlers #########

}
######### Filter #########

######### Output #########
output {
  # Send to console
  if "true" in [index] {
    stdout {
      codec => rubydebug
    }

    # Send directly to local Elasticsearch
    elasticsearch {
      # TODO: create template
      # template => ""
      index => "difi-%{+YYYY.MM.dd}"
      # template_overwrite => true
    }
  }
}
######### Output #########
