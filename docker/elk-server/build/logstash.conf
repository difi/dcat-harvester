######### Input #########
input {
  file {
    path => "/usr/local/tomcat/logs/dcat-harvester.log"
    start_position => "beginning"
    # setting sincedb_path to /dev/null will ensure we always parse logs fresh every time - useful for testing
    # sincedb_path => "/dev/null"
  }
  file {
    path => "/usr/local/tomcat/logs/dcat-admin.log"
    start_position => "beginning"
    # setting sincedb_path to /dev/null will ensure we always parse logs fresh every time - useful for testing
    # sincedb_path => "/dev/null"
  }
}
######### Input #########

######### Filter #########
filter {
  # Extract event severity, timestamp and logevent type
  grok {
    match => { "message" => "%{%{DATESTAMP:timestamp} %{WORD:severity}.+?([a-zA-Z]+\.)+.+?- \[%{WORD:logger}\] \[%{WORD:result}\] %{GREEDYDATA:rawContent}(\n%{GREEDYDATA:error}|$)}" }
      tag_on_failure => [ "fail" ]
  }
  grok {
    match => { "rawContent" => "%{DATA:event}: %{GREEDYDATA:content}" }
    tag_on_failure => [ "fail" ]
  }
  kv {
    source => "content"
    field_split => ", "
    value_split => "="
  }
  mutate {
    remove_field => [ "content, rawContent, logger" ]
  }
  if "null" in [error] {
    mutate {
      remove_field => [ "error" ]
    }
  }
}
######### Filter #########

######### Output #########
output {
  if "fail" in [tags] {
  } else {
    # Send to console - useful for testing
     stdout {
     codec => rubydebug
     }

    # Send directly to local Elasticsearch
    #elasticsearch {
      # TODO: create template
      # template => ""
    #  index => "difi-%{+YYYY.MM.dd}"
      # template_overwrite => true
    #}
  }
}
######### Output #########
